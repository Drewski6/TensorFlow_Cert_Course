{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Fundamentals\n",
    "*********************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Starting this notebook to follow along with the udemy tutorial.\n",
    "- I named this notebook the same name as the provided course work, but added a p at the end of the number in the title to indicate to the vimwiki_load script that this is a personal version and I want to upload this particular version to my vimwiki."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this notebook, we're going to cover some of the most fundamental concepts of tensors using TensorFlow.\n",
    "- Specifically we're going to cover:\n",
    "    - Intro to tensors\n",
    "    - Getting info from tensors\n",
    "    - Manipulating tensors\n",
    "    - Tensors & NumPy\n",
    "    - Using @tf.function (a way to speed up your regular Python functions)\n",
    "    - Using GPUs with TensorFlow (or TPUs)\n",
    "    - Exercises to try for yourself!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a tensor with constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=7>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = tf.constant(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get the dimensions of a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a vector.\n",
    "    - Note we passed a python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([10, 10], dtype=int32)>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = tf.constant([10, 10])\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get the dimension of a vector (which remember is still a constant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 7, 10]], dtype=int32)>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = tf.constant([[10, 7],\n",
    "                      [7, 10]])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using different data types.\n",
    "- When creating a constant tensor, by default, we are using the int32 for our data type.\n",
    "- We can use another type like float 16 and use different data types.\n",
    "- This is imporant to know, because by chaning the dtype keyword argument, you can change the type of data being stored, which may come in handy for debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float16, numpy=\n",
       "array([[10.,  7.],\n",
       "       [ 3.,  2.],\n",
       "       [ 8.,  9.]], dtype=float16)>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "another_matrix = tf.constant([[10., 7.],\n",
    "                              [3., 2.],\n",
    "                              [8., 9.]], dtype=tf.float16)\n",
    "another_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "another_matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2, 3), dtype=int32, numpy=\n",
       "array([[[ 1,  2,  3],\n",
       "        [ 4,  5,  6]],\n",
       "\n",
       "       [[ 7,  8,  9],\n",
       "        [10, 11, 12]],\n",
       "\n",
       "       [[13, 14, 15],\n",
       "        [16, 17, 18]]], dtype=int32)>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tf.constant([[[1, 2, 3],\n",
    "                       [4, 5, 6]],\n",
    "                      [[7, 8, 9],\n",
    "                       [10, 11, 12]],\n",
    "                      [[13, 14, 15],\n",
    "                       [16, 17, 18]]])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Essencially, when referring to tensors we are referring to any object that is a tensor object in TensorFlow. Even if the tensor object is only a 0 dimensional scalar, in TensorFlow, it's still referred to as a tensor.\n",
    "- What have we created?\n",
    "    - Scalar = a single number.\n",
    "    - Vector = a number with a direction.\n",
    "    - Matrix = a 2 dimensional array of numbers.\n",
    "    - Tensor = a n-dimensinal array of numbers (where n can be any number)\n",
    "        - 0 dimension is a scalar; 2 dimension is an matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating tensors with tf.Variable\n",
    "\n",
    "- Create a variable tensor and a constant tensor and compare and contrast them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'Variable:0' shape=(2,) dtype=int32, numpy=array([10,  7], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=int32, numpy=array([10,  7], dtype=int32)>)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "changeable_tensor = tf.Variable([10, 7])\n",
    "unchangeable_tensor = tf.constant([10, 7])\n",
    "changeable_tensor, unchangeable_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2,) dtype=int32, numpy=array([7, 7], dtype=int32)>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Does not work\n",
    "# changeable_tensor[0] = 7\n",
    "# Works\n",
    "changeable_tensor[0].assign(7)\n",
    "changeable_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([10,  7], dtype=int32)>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Does not work\n",
    "# unchangeable_tensor[0] = 7\n",
    "# Still does not work\n",
    "# unchangeable_tensor[0].assign(7)\n",
    "unchangeable_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating random tensors\n",
    "\n",
    "- Random tensors are tensors of some arbitrary size which contain random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[-0.7565803 , -0.06854702],\n",
       "        [ 0.07595026, -1.2573844 ],\n",
       "        [-0.23193765, -1.8107855 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[-0.7565803 , -0.06854702],\n",
       "        [ 0.07595026, -1.2573844 ],\n",
       "        [-0.23193765, -1.8107855 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=bool, numpy=\n",
       " array([[ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True]])>)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_1 = tf.random.Generator.from_seed(42)\n",
    "random_1 = random_1.normal(shape=(3, 2))\n",
    "random_2 = tf.random.Generator.from_seed(42)\n",
    "random_2 = random_2.normal(shape=(3, 2))\n",
    "random_1, random_2, random_1 == random_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffling the order of tensors\n",
    "\n",
    "- Why shuffle the order of values in a tensor?\n",
    "    - If the tensor represents our data like a group of pictures, if the pictures are ordered in any significant way, then that could teach the neural network with some sort of bias for items in the beginning of the list if it's not uniform.\n",
    "    - We can shuffle the data so that it is as close to random as possible so we get try to eliminate any sort of bias towards items in the beginning of the list.\n",
    "- Shuffle data so that inherant order doesn't affect learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_shuffled = tf.constant([[10, 7],\n",
    "                            [3, 4],\n",
    "                            [2, 5]])\n",
    "not_shuffled.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the shuffle function lets us shuffle the elements of the tensor along the first dimension.\n",
    "- This means that the second dimension is left unaffected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[ 2,  5],\n",
       "       [10,  7],\n",
       "       [ 3,  4]], dtype=int32)>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.shuffle(not_shuffled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that even if we set the seed for the shuffle, we still get different results each time we use the shuffle command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 3,  4],\n",
       "       [ 2,  5]], dtype=int32)>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.shuffle(not_shuffled, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is because the shuffle actaully depends on 2 random seeds, a global level seed and an operation level seed.\n",
    "- When we set the global and the operation level seeds to the same thing, now we see the values no not change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 3,  4],\n",
       "       [ 2,  5]], dtype=int32)>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "tf.random.shuffle(not_shuffled, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lesson: Read through TensorFlow documentation on tf.random.set_seed\n",
    "\n",
    "- Big take away: If you want to shuffle your data in a reproducable way, you'll need to set both the global and operational seeds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating tensors from NumPy arrays\n",
    "\n",
    "- TensorFlow has many of the same array operations as numpy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 7), dtype=float32, numpy=\n",
       "array([[1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.ones([10, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Either of these ways work\n",
    "tf.zeros([10, 7])\n",
    "tf.zeros(shape=(3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can also turn array from NumPy into tensors.\n",
    "- The main difference between NumPy arrays and TensorFlow tensors is that tensors can be run on a GPU (which is much faster for numerical computing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24], dtype=int32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a NumPy array\n",
    "import numpy as np\n",
    "numpy_A = np.arange(1, 25, dtype=np.int32)\n",
    "numpy_A\n",
    "\n",
    "# X = tf.constant(some_matrix)  # Capital for matrix or tensor.\n",
    "# y = tf.constant(vector)       # Lowercase for vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(24,), dtype=int32, numpy=\n",
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24], dtype=int32)>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert our NumPy array to a tensor.\n",
    "A = tf.constant(numpy_A)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We cannot reshape our tensor like we can in NumPy because we imported it as a constant, but we can reimport it and give it a shape that we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 4), dtype=int32, numpy=\n",
       "array([[[ 1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12]],\n",
       "\n",
       "       [[13, 14, 15, 16],\n",
       "        [17, 18, 19, 20],\n",
       "        [21, 22, 23, 24]]], dtype=int32)>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape our tensor.\n",
    "A = tf.constant(numpy_A, shape=(2, 3, 4))\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting information from our tensors\n",
    "\n",
    "When dealing with tensors you probably want to be aware of the following attributes:\n",
    "- Shape\n",
    "- Rank\n",
    "- Axis or dimension\n",
    "- Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 4, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a rank 4 tensor (4 dimensions)\n",
    "rank_4_tensor = tf.zeros(shape=(2, 3, 4, 5))\n",
    "rank_4_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we can use a couple different methods/functions to get some characteristics of our tensors.\n",
    "- size includes how many elements are in the tensor.\n",
    "    - size is probably used the least often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 3, 4, 5]), 4, <tf.Tensor: shape=(), dtype=int32, numpy=120>)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_4_tensor.shape, rank_4_tensor.ndim, tf.size(rank_4_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How to get various attributes of our tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatype of each element: <dtype: 'float32'>\n",
      "Number of dimensions (rank): 4\n",
      "Shape of tensor: (2, 3, 4, 5)\n",
      "Elements along the 0 axis: 2\n",
      "Elements along the last axis: 5\n",
      "Total number of elements in our tensor: tf.Tensor(120, shape=(), dtype=int32)\n",
      "Total number of elements in our tensor: 120\n"
     ]
    }
   ],
   "source": [
    "print(\"Datatype of each element:\", rank_4_tensor.dtype)\n",
    "print(\"Number of dimensions (rank):\", rank_4_tensor.ndim)\n",
    "print(\"Shape of tensor:\", rank_4_tensor.shape)\n",
    "print(\"Elements along the 0 axis:\", rank_4_tensor.shape[0])\n",
    "print(\"Elements along the last axis:\", rank_4_tensor.shape[-1])\n",
    "print(\"Total number of elements in our tensor:\", tf.size(rank_4_tensor))\n",
    "print(\"Total number of elements in our tensor:\", tf.size(rank_4_tensor).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing and expanding tensors\n",
    "\n",
    "- Tensors can be indexed just like Python lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2, 2), dtype=float32, numpy=\n",
       "array([[[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the first two elements in each dimension.\n",
    "rank_4_tensor[:2, :2, :2, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 1, 5), dtype=float32, numpy=array([[[[0., 0., 0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the first element from each dimension from each index except for the final one.\n",
    "rank_4_tensor[:1, :1, :1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sometimes we may want to change the shape of a tensor:\n",
    "    - We can add a dimension to a tensor or reshape a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[1, 2],\n",
       "       [3, 4]], dtype=int32)>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a rank 2 tensor (2 dimensions)\n",
    "rank_2_tensor = tf.constant([[1, 2], [3, 4]])\n",
    "rank_2_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 2]), 2)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_2_tensor.shape, rank_2_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 4], dtype=int32)>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the last item of each row of our rank 2 tensor.\n",
    "rank_2_tensor[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To add dimensions might not seem helpful now, but will be helpful when we are dealing with data and we need the shapes of the data to match in order to run it through a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 1), dtype=int32, numpy=\n",
       "array([[[1],\n",
       "        [2]],\n",
       "\n",
       "       [[3],\n",
       "        [4]]], dtype=int32)>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add in extra dimension into our rank 2 tensor.\n",
    "rank_3_tensor = rank_2_tensor[..., tf.newaxis]      # ... means the same as :,:,:,...\n",
    "rank_3_tensor = rank_2_tensor[:, :, tf.newaxis]     # This way you don't have to type out all the :,:,:, etc\n",
    "rank_3_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 1), dtype=int32, numpy=\n",
       "array([[[1],\n",
       "        [2]],\n",
       "\n",
       "       [[3],\n",
       "        [4]]], dtype=int32)>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternative to tf.newaxis. Same output.\n",
    "tf.expand_dims(rank_2_tensor, axis=-1)      # \"-1\" axis means last axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If we change the axis in the above example, we can change where the extra dimension is added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating Tensors (Tensor Operations)\n",
    "\n",
    "##### Basic Operations\n",
    "    '+', '-', '*', '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[20, 17],\n",
       "       [12, 13]], dtype=int32)>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can add values to a tensor using the addition operator.\n",
    "tensor = tf.constant([[10, 7], \n",
    "                      [2, 3]])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that we don't always want to change the original tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[100,  70],\n",
       "       [ 20,  30]], dtype=int32)>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplication\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 0, -3],\n",
       "       [-8, -7]], dtype=int32)>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtraction\n",
    "tensor - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[100,  70],\n",
       "       [ 20,  30]], dtype=int32)>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use the TensorFlow built-in functions as well.\n",
    "tf.multiply(tensor, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can do regular python operations like + - * / but you can also use some build-in functions.\n",
    "- If you're dealing with really large tensors, the built-in functions will be faster on a GPU, so go with this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Multiplication\n",
    "\n",
    "- In machine learning, matrix multiplication is one of the most common operations.\n",
    "- Until this point, we've been looking at \"element-wise\" operations.\n",
    "- Multiplication can be either element-wise or can be what's called a dot product.\n",
    "    - When multiplying a matrix by a scalar (a single number), we do element wise.\n",
    "    - When multiplying a matrix by another matrix we do what's called the dot product.\n",
    "    - Read more on dot products: {{http://matrixmultiplication.xyz/}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[10  7]\n",
      " [ 2  3]], shape=(2, 2), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[114,  91],\n",
       "       [ 26,  23]], dtype=int32)>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix Multiplication in TensorFlow\n",
    "print(tensor)\n",
    "# Dot product of two tensors.\n",
    "tf.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[10  7]\n",
      " [ 2  3]], shape=(2, 2), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[100,  49],\n",
       "       [  4,   9]], dtype=int32)>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Product element-wise of two tensors.\n",
    "print(tensor)\n",
    "tensor * tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[15, 27],\n",
       "       [ 6,  7],\n",
       "       [26, 63]], dtype=int32)>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example matrix multiplication from matrixmultiplication.xyz\n",
    "tensor_1 = tf.constant([[1, 2, 1], [0, 1, 0], [2, 3, 4]])\n",
    "tensor_2 = tf.constant([[2, 5], [6, 7], [1, 8]])\n",
    "tf.matmul(tensor_1, tensor_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[15, 27],\n",
       "       [ 6,  7],\n",
       "       [26, 63]], dtype=int32)>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To perform matrix multiplication in python with a built-in operator, we use the @ symbol.\n",
    "tensor_1 @ tensor_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which matrixes can we multipy together?\n",
    "X = tf.constant([[1, 2], [3, 4], [5, 6]])\n",
    "Y = tf.constant([[7, 8], [9, 10], [11, 12]])\n",
    "# X @ Y       # Results in an error because matrix sizes are incompatible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are two rules that our tensors (or matrices) need to fulfill if we're going to matrix multiply them:\n",
    "    - The inner dimensions must match.\n",
    "    - The resulting matrix has the shape of the outer dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 7  8  9]\n",
      " [10 11 12]], shape=(2, 3), dtype=int32)\n",
      "(3, 2)\n",
      "(2, 3)\n",
      "tf.Tensor(\n",
      "[[ 27  30  33]\n",
      " [ 61  68  75]\n",
      " [ 95 106 117]], shape=(3, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 76 100]\n",
      " [103 136]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# We can change the shape of Y.\n",
    "Y = tf.reshape(Y, shape=(2, 3))\n",
    "print(Y)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(tf.matmul(X, tf.reshape(Y, shape=(2, 3))))\n",
    "print(tf.matmul(Y, tf.reshape(X, shape=(3, 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       " array([[1, 3, 5],\n",
       "        [2, 4, 6]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       " array([[1, 2, 3],\n",
       "        [4, 5, 6]], dtype=int32)>)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can also do this with transpose.\n",
    "X, tf.transpose(X), tf.reshape(X, shape=(2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- By default, transpose will flip the axis of the matrix, while a regular reshape will maintain the same order of the matrix, but change how they're grouped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "# Try matrix multiplication with transpose rather than reshape.\n",
    "print(Y.shape)\n",
    "print(X.shape)\n",
    "# tf.matmul(tf.transpose(X), Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dot Product\n",
    "\n",
    "- Matrix multiplication is also referred to as the dot product.\n",
    "- You can perform matrix multiplication using:\n",
    "    - `tf.matmul()`\n",
    "    - `tf.tesnordot()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[ 7,  8],\n",
       "        [ 9, 10],\n",
       "        [11, 12]], dtype=int32)>)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = tf.reshape(Y, shape=(3, 2))\n",
    "X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 89,  98],\n",
       "       [116, 128]], dtype=int32)>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exmaple of tensordot.\n",
    "tf.tensordot(tf.transpose(X), Y, axes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 23,  29,  35],\n",
       "       [ 53,  67,  81],\n",
       "       [ 83, 105, 127]], dtype=int32)>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform matrix multiplication between X and Y (transposed).\n",
    "tf.matmul(X, tf.transpose(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 27,  30,  33],\n",
       "       [ 61,  68,  75],\n",
       "       [ 95, 106, 117]], dtype=int32)>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform matrix multiplication between X and Y (reshaped).\n",
    "tf.matmul(X, tf.reshape(Y, shape=(2, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Per the instructor, there are 2 common errors when building neural networks:\n",
    "    - Tensors are mis-shaped and need to be reshaped.\n",
    "    - Matrix multiplication works, but something happened during the reshaping process that caused unexpected data (reshape vs transpose).\n",
    "- That is to say, if something isn't working, it can be really good to use print statements to take a good look at your data and make sure everything is where it should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Y:\n",
      "tf.Tensor(\n",
      "[[ 7  8]\n",
      " [ 9 10]\n",
      " [11 12]], shape=(3, 2), dtype=int32) \n",
      "\n",
      "Y reshaped to (2, 3):\n",
      "tf.Tensor(\n",
      "[[ 7  8  9]\n",
      " [10 11 12]], shape=(2, 3), dtype=int32) \n",
      "\n",
      "Y transponsed:\n",
      "tf.Tensor(\n",
      "[[ 7  9 11]\n",
      " [ 8 10 12]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Check the values of Y, reshape Y and transpose Y\n",
    "print(\"Normal Y:\")\n",
    "print(Y, \"\\n\")\n",
    "print(\"Y reshaped to (2, 3):\")\n",
    "print(tf.reshape(Y, (2, 3)), \"\\n\")\n",
    "print(\"Y transponsed:\")\n",
    "print(tf.transpose(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generally when performing matrix multiplication on two tensors and one of the axes doesn't line up, you will transpose (rather than reshape) one of the tensors to satisfy the matrix multiplication rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([83, 63, 37, 75], dtype=int32)>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = tf.constant([3, 4, 2])\n",
    "B = tf.constant([[13, 9, 7, 15], [8, 7, 4, 6], [6, 4, 0, 3]])\n",
    "tf.tensordot(A, B, axes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I just noticed that matmul is really for mutliplying matrices and does not work when multiplying a matrix and a vector.\n",
    "- If you want to multiply a matrix and a vector, tensordot is the way to go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the DataType of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new tensor with default datatype (float32)\n",
    "B = tf. constant([1.7, 7.4])\n",
    "B.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.int32"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new tensor with int32 datatype by using integers with no decimals.\n",
    "C = tf.constant([7, 10])\n",
    "C.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In some circumstances, you may need to run with different data types.\n",
    "    - 16 bit data types run faster but carry less precision.\n",
    "- To change, use the cast method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float16, numpy=array([1.7, 7.4], dtype=float16)>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change from float32 to float16 (reduced precision).\n",
    "B = tf.cast(B, dtype=tf.float16)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 7., 10.], dtype=float32)>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change from int32 to float32\n",
    "E = tf.cast(C, dtype=tf.float32)\n",
    "E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating Tensors\n",
    "\n",
    "- Aggregating tensors is condensing tensors from multiple values down to a smaller amount of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([ -7, -10], dtype=int32)>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the absolute values.\n",
    "D = tf.constant([-7, -10])\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([ 7, 10], dtype=int32)>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.abs(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's go through the following forms of aggregation:\n",
    "    - Get the minimum.\n",
    "    - Get the maximum.\n",
    "    - Get the mean of a tensor.\n",
    "    - Get the sum of a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int64, numpy=\n",
       "array([87, 27, 80, 89, 30, 48, 99, 27, 21,  1, 36, 19, 52, 34, 63, 18, 63,\n",
       "        8, 74, 87, 73, 88, 57, 26,  4, 16, 91, 34, 83, 97, 16, 60, 66, 84,\n",
       "       62,  7, 20, 66, 20, 51, 40, 60, 10, 32,  5, 37, 18, 33, 96, 34])>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will be using this tensor for the exercise.\n",
    "M = tf.constant(np.random.randint(0, 100, size=50))\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=1>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the minimum of a tensor.\n",
    "tf.reduce_min(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=99>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the maximum of a tensor.\n",
    "tf.reduce_max(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=46>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the mean of a tensor.\n",
    "tf.reduce_mean(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=2349>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the sum of a tensor.\n",
    "tf.reduce_sum(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TensorFlow tends to put \"reduce_\" in front of aggregate functions.\n",
    "- Find the variance and the standard deviation of the tensor before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = tf.cast(M, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=855.05963>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the variance of a tensor.\n",
    "tf.math.reduce_variance(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=29.241404>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_std(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Had to cast to a float32 type.\n",
    "- Some functions in tensor flow require certain types in order to work.\n",
    "- If you ever get a type error like I did, the best thing to do is look in the documentation and look at the examples and see what types they use.\n",
    "- Gernally, float 32 is the standard type in tensor flow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Challenge: Find the positional maximum and minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 5), dtype=float64, numpy=\n",
       "array([[-2.21254601, -0.92559599, -0.00317401, -0.28343482, -1.20978237],\n",
       "       [-0.72225741, -0.07216006,  1.9986215 , -0.05645002,  0.84393116],\n",
       "       [ 0.26472602, -0.5783191 , -0.00677912, -0.03398538,  0.58780145],\n",
       "       [ 1.01016466, -0.75746784, -0.11586818, -0.27276934, -0.73359652]])>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = tf.constant(np.random.randn(4, 5))\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position max: tf.Tensor([2 2 4 0], shape=(4,), dtype=int64)\n",
      "Position min: tf.Tensor([0 0 1 1], shape=(4,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(\"Position max:\", tf.argmax(L, axis=1))\n",
    "print(\"Position min:\", tf.argmin(L, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squeezing a tensor (removing all single dimensions)\n",
    "\n",
    "- The squeeze function will get rid of extra dimentions of size 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 1, 1, 50), dtype=float32, numpy=\n",
       "array([[[[[0.6645621 , 0.44100678, 0.3528825 , 0.46448255, 0.03366041,\n",
       "           0.68467236, 0.74011743, 0.8724445 , 0.22632635, 0.22319686,\n",
       "           0.3103881 , 0.7223358 , 0.13318717, 0.5480639 , 0.5746088 ,\n",
       "           0.8996835 , 0.00946367, 0.5212307 , 0.6345445 , 0.1993283 ,\n",
       "           0.72942245, 0.54583454, 0.10756552, 0.6767061 , 0.6602763 ,\n",
       "           0.33695042, 0.60141766, 0.21062577, 0.8527372 , 0.44062173,\n",
       "           0.9485276 , 0.23752594, 0.81179297, 0.5263394 , 0.494308  ,\n",
       "           0.21612847, 0.8457197 , 0.8718841 , 0.3083862 , 0.6868038 ,\n",
       "           0.23764038, 0.7817228 , 0.9671384 , 0.06870162, 0.79873943,\n",
       "           0.66028714, 0.5871513 , 0.16461694, 0.7381023 , 0.32054043]]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor to get started.\n",
    "tf.random.set_seed(42)\n",
    "U = tf.constant(tf.random.uniform(shape=[1, 1, 1, 1, 50]))\n",
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 1, 1, 1, 50])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now with the squeeze function, we can reduce the dimension down so that only those that hold information remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=float32, numpy=\n",
       "array([0.6645621 , 0.44100678, 0.3528825 , 0.46448255, 0.03366041,\n",
       "       0.68467236, 0.74011743, 0.8724445 , 0.22632635, 0.22319686,\n",
       "       0.3103881 , 0.7223358 , 0.13318717, 0.5480639 , 0.5746088 ,\n",
       "       0.8996835 , 0.00946367, 0.5212307 , 0.6345445 , 0.1993283 ,\n",
       "       0.72942245, 0.54583454, 0.10756552, 0.6767061 , 0.6602763 ,\n",
       "       0.33695042, 0.60141766, 0.21062577, 0.8527372 , 0.44062173,\n",
       "       0.9485276 , 0.23752594, 0.81179297, 0.5263394 , 0.494308  ,\n",
       "       0.21612847, 0.8457197 , 0.8718841 , 0.3083862 , 0.6868038 ,\n",
       "       0.23764038, 0.7817228 , 0.9671384 , 0.06870162, 0.79873943,\n",
       "       0.66028714, 0.5871513 , 0.16461694, 0.7381023 , 0.32054043],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U_squeezed = tf.squeeze(U)\n",
    "U_squeezed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([50])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U_squeezed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now the extra empty dimensions are empty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding tenosors\n",
    "\n",
    "- One-hot encoding is a form of numerical encoding.\n",
    "- Essencially, we take data and spread it out over a larger array based on another variable.\n",
    "- The example given is like for a photo we have red, gree, and blue values.\n",
    "    - We can take each of those colors and assign them numbers.\n",
    "    - Like this, we're doing one-hot encoding for the colors in an image.\n",
    "- Another example is when dealing with words, depending on the application, we can't always pass words to our neural network. But we can one-hot encode them and the pass them as a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of indices\n",
    "some_list = [0, 1, 2, 3, 2]\n",
    "\n",
    "# One hot encode out list of indices.\n",
    "tf.one_hot(some_list, depth=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that every time we see a unique item, we add a column and when we repeat an item we place it in the same column as where we placed it the first time we saw it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 4), dtype=string, numpy=\n",
       "array([[b'Yo I love deep learning', b'I also like to dance',\n",
       "        b'I also like to dance', b'I also like to dance'],\n",
       "       [b'I also like to dance', b'Yo I love deep learning',\n",
       "        b'I also like to dance', b'I also like to dance'],\n",
       "       [b'I also like to dance', b'I also like to dance',\n",
       "        b'Yo I love deep learning', b'I also like to dance'],\n",
       "       [b'I also like to dance', b'I also like to dance',\n",
       "        b'I also like to dance', b'Yo I love deep learning'],\n",
       "       [b'I also like to dance', b'I also like to dance',\n",
       "        b'Yo I love deep learning', b'I also like to dance']],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify custom values for one hot encoding.\n",
    "tf.one_hot(some_list, depth=4, on_value='Yo I love deep learning', off_value='I also like to dance')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What we do here were we change the default from 0 and 1 to strings is very rarely used in neural networks since we normally want numeric encoding. But still fun to know that this is an option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experimenting a little with the one_hot function.\n",
    "tf.one_hot(some_list, depth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying out more tensor math operations\n",
    "\n",
    "##### Squaring, log, square root\n",
    "\n",
    "- Just quickly, you can replicate the numpy arange function in tensorflow with the range function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(9,), dtype=int32, numpy=array([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)>,\n",
       " <tf.Tensor: shape=(9,), dtype=int32, numpy=array([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)>)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new tensor.\n",
    "H = tf.range(1, 10)\n",
    "I = tf.constant(np.arange(1, 10, dtype='int32'))\n",
    "H, I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=int32, numpy=array([ 1,  4,  9, 16, 25, 36, 49, 64, 81], dtype=int32)>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Square a tensor.\n",
    "tf.square(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Square root. (Will error. sqrt method requires non-int type)\n",
    "# tf.sqrt(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=float32, numpy=\n",
       "array([1.       , 1.4142135, 1.7320508, 2.       , 2.2360678, 2.4494896,\n",
       "       2.6457512, 2.828427 , 3.       ], dtype=float32)>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Square root.\n",
    "tf.sqrt(tf.cast(H, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=float32, numpy=\n",
       "array([0.       , 0.6931472, 1.0986123, 1.3862944, 1.609438 , 1.7917595,\n",
       "       1.9459102, 2.0794415, 2.1972246], dtype=float32)>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the log.\n",
    "tf.math.log(tf.cast(H, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors and NumPy\n",
    "\n",
    "- TensorFlow interacts beatufly with the NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 3.,  7., 10.])>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor directly from a NumPy array.\n",
    "\n",
    "J = tf.constant(np.array([3., 7., 10.]))\n",
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.,  7., 10.]), numpy.ndarray)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert out rensor back to a NumPy array.\n",
    "np.array(J), type(np.array(J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.,  7., 10.]), numpy.ndarray)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert tensor J to a NumPy array.\n",
    "J.numpy(), type(J.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If we ever find that there is some functionality that we want to use on a tensor that we can't do in tensorflow, we can always convert to a numpy array, change it and then convert back if we need to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J = tf.constant([3.])\n",
    "J.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=int64, numpy=array([3, 4, 5])>,\n",
       " <tf.Tensor: shape=(3,), dtype=int32, numpy=array([3, 4, 5], dtype=int32)>)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The default types of each are slightly different.\n",
    "numpy_J = tf.constant(np.array([3, 4, 5]))\n",
    "tensor_J = tf.constant([3, 4, 5])\n",
    "numpy_J, tensor_J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that the default types for numpy is usually either int64 or float 64 while the default types for tensorflow is usually int32 and float32."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding access to GPUs\n",
    "\n",
    "- Again note that numpy arrays must be processed through a CPU while a tensorflow array can be process through a GPU or a TPU.\n",
    "- If we want to see if we have access to a GPU we can use a special function to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check GPU access.\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If in Google Colab we have free access to google GPUs.\n",
    "- To configure this:\n",
    "    - Runtime > Change Runtime Type > Hardware accelerator.\n",
    "    - Here you can change the option from None to either GPU or TPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/zsh: /home/drew/anaconda3/envs/tf_cert_3/lib/libtinfo.so.6: no version information available (required by /usr/bin/zsh)\n",
      "Tue Oct 25 14:50:09 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.76       Driver Version: 515.76       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   57C    P0    26W /  N/A |   4683MiB /  6144MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2381      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    0   N/A  N/A      5507      C   ...envs/tf_cert_3/bin/python     4675MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If you have access to a CUDA-enabled GPU, TensorFlow with automatically use it whenever possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Curriculum\n",
    "\n",
    "- These are some extra challenges to do to make sure I understand all the content of this chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=string, numpy=array([b'1', b'2', b'3', b'4', b'5'], dtype=object)>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try to use a command we haven't talked about by going through the documentation.\n",
    "# as_string converts the entire contents of a tensor into strings.\n",
    "X = tf.constant([1, 2, 3, 4, 5])\n",
    "tf.as_string(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15,)\n",
      "[ 4.78 10.2   1.52  5.53  2.76 11.62  1.47 10.19  7.89 11.33 15.18 13.81\n",
      " 11.3  15.92 16.94]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=140.44>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate your most recent grocery bill with tensors.\n",
    "groc_list = tf.constant([3.95, 7.88, 15.98, 2.77, 7.11, 6.33])\n",
    "groc_list_2 = np.random.uniform(1, 20, (15))\n",
    "print(groc_list_2.shape)\n",
    "groc_list_2 = groc_list_2.round(decimals=2)\n",
    "print(groc_list_2)\n",
    "\n",
    "tf.reduce_sum(groc_list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=463.5266170548941>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How would you calucate for the month or for the year.\n",
    "groc_list_jan = np.random.uniform(1, 20, (15))\n",
    "groc_list_feb = np.random.uniform(1, 20, (15))\n",
    "groc_list_mar = np.random.uniform(1, 20, (15))\n",
    "groc_list_master = tf.constant([[groc_list_jan], [groc_list_feb], [groc_list_mar]])\n",
    "tf.reduce_sum(groc_list_master)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow 2 quickstart for beginners\n",
    "\n",
    "- Doing the quickstart guide for beginners from here: \n",
    "    - {{https://www.tensorflow.org/tutorials/quickstart/beginner}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we are going to use the MNIST dataset which is a dataset of handwritten numbers and we will use this to train a neural network to determine which digit is written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f791822c160>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)), \n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.07587474, -0.07740404, -0.75248694,  0.07194675,  0.13117404,\n",
       "         0.23845708,  0.5949922 ,  0.34162122,  0.56129944,  0.2337757 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model(x_train[:1]).numpy()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07696058, 0.07684298, 0.03912185, 0.08922085, 0.09466478,\n",
       "        0.1053855 , 0.15052967, 0.1168381 , 0.1455424 , 0.1048933 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2501302"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_train[:1], predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "                loss=loss_fn,\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 777us/step - loss: 0.2981 - accuracy: 0.9119\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 1s 770us/step - loss: 0.1431 - accuracy: 0.9576\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 789us/step - loss: 0.1062 - accuracy: 0.9689\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 1s 787us/step - loss: 0.0889 - accuracy: 0.9727\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 775us/step - loss: 0.0740 - accuracy: 0.9765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f791822f7f0>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.0742 - accuracy: 0.9776 - 258ms/epoch - 823us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07416711747646332, 0.9775999784469604]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([\n",
    "    model,\n",
    "    tf.keras.layers.Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
       "array([[6.2318428e-08, 1.6473855e-08, 3.1926804e-05, 8.9347857e-04,\n",
       "        3.4310846e-11, 5.9986479e-07, 3.3044140e-12, 9.9906820e-01,\n",
       "        9.7423776e-07, 4.7094868e-06],\n",
       "       [1.0436622e-08, 9.5779096e-06, 9.9993908e-01, 3.8101746e-06,\n",
       "        2.4911851e-14, 5.9991125e-06, 6.2091203e-08, 2.5297809e-12,\n",
       "        4.1494546e-05, 7.6031514e-11],\n",
       "       [6.9193725e-08, 9.9632287e-01, 2.5629802e-04, 9.0515168e-06,\n",
       "        6.0915139e-05, 4.8611078e-06, 3.2811258e-06, 3.0361447e-03,\n",
       "        3.0436637e-04, 2.2330225e-06],\n",
       "       [9.9904293e-01, 5.5301550e-09, 1.8553127e-04, 2.1143505e-06,\n",
       "        1.6330179e-06, 5.6430741e-05, 8.3140432e-05, 1.2813536e-04,\n",
       "        1.3666349e-07, 4.9984118e-04],\n",
       "       [2.0341162e-05, 1.0214822e-09, 1.2952049e-04, 1.3217968e-07,\n",
       "        9.6183187e-01, 7.9696347e-06, 3.8984828e-05, 1.7022662e-04,\n",
       "        9.0082940e-06, 3.7791826e-02]], dtype=float32)>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_model(x_test[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('tf_cert_3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ffabda09fb0e852a0a578aef27687424258d5d6af73bd1919bef7d65934b3c08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
